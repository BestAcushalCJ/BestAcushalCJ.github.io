{"meta":{"title":"大山","subtitle":"这是一个热爱技术、热爱烹饪的肥宅","description":"孤高锦瑟笑游侠","author":"大山","url":"http://yoursite.com"},"pages":[{"title":"archives","date":"2018-09-01T12:19:26.000Z","updated":"2018-09-01T12:20:05.974Z","comments":true,"path":"archives/index.html","permalink":"http://yoursite.com/archives/index.html","excerpt":"","text":""},{"title":"categories","date":"2018-09-01T12:18:15.000Z","updated":"2018-09-03T11:21:03.775Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-09-01T11:22:42.000Z","updated":"2018-09-01T11:24:46.112Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Coursera机器学习笔记(四) - Octave教程","slug":"machine_learning_note_04","date":"2018-09-06T15:38:08.933Z","updated":"2018-09-06T15:58:46.801Z","comments":true,"path":"2018/09/06/machine_learning_note_04/","link":"","permalink":"http://yoursite.com/2018/09/06/machine_learning_note_04/","excerpt":"MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} }); 课程地址：Octave Tutorial课程Wiki：Octave Tutorial参考：Octave documentation pages&emsp;&emsp;Introduction to Octave 基本操作四则运算12345678octave:1&gt; 5+6ans = 11octave:2&gt; 3-2ans = 1octave:3&gt; 5*8ans = 40octave:4&gt; 1/2ans = 0.50000","text":"MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} }); 课程地址：Octave Tutorial课程Wiki：Octave Tutorial参考：Octave documentation pages&emsp;&emsp;Introduction to Octave 基本操作四则运算12345678octave:1&gt; 5+6ans = 11octave:2&gt; 3-2ans = 1octave:3&gt; 5*8ans = 40octave:4&gt; 1/2ans = 0.50000 逻辑运算12345678910octave:6&gt; 1 == 2ans = 0octave:7&gt; 1 ~= 2ans = 1octave:8&gt; 1 &amp;&amp; 0ans = 0octave:9&gt; 1 || 0ans = 1octave:10&gt; xor(1,0)ans = 1 其他更改提示符：12octave:11&gt; PS1(&apos;&gt;&gt; &apos;)&gt;&gt; 添加分号可抑制输出：1234&gt;&gt; a = 1a = 1&gt;&gt; a = 1;&gt;&gt; 圆周率$\\pi$：12&gt;&gt; a = pia = 3.1416 常数$e$：12&gt;&gt; eans = 2.7183 格式化输出：12345678910&gt;&gt; disp(sprintf(&apos;6 decimals: %0.6f&apos;, a))6 decimals: 3.141593&gt;&gt; disp(sprintf(&apos;6 decimals: %0.2f&apos;, a))6 decimals: 3.14&gt;&gt; format long&gt;&gt; aa = 3.14159265358979&gt;&gt; format short&gt;&gt; aa = 3.1416 矩阵构造一个矩阵，方式一：123456&gt;&gt; A = [1 2; 3 4; 5 6;]A = 1 2 3 4 5 6 构造一个矩阵，方式二：123456789&gt;&gt; A = [1 2;&gt; 3 4;&gt; 5 6;&gt; ]A = 1 2 3 4 5 6 构造一个横向量：1234&gt;&gt; v = [1 2 3]v = 1 2 3 构造一个列向量：123456&gt;&gt; v = [1; 2; 3]v = 1 2 3 从1到2，每次递增0.1：1234567891011121314&gt;&gt; v = 1:0.1:2v = Columns 1 through 5: 1.0000 1.1000 1.2000 1.3000 1.4000 Columns 6 through 10: 1.5000 1.6000 1.7000 1.8000 1.9000 Column 11: 2.0000 从1到6，每次递增1(默认)：1234&gt;&gt; v = 1:6v = 1 2 3 4 5 6 所有元素均为1：12345&gt;&gt; ones(2, 3)ans = 1 1 1 1 1 1 每个元素乘以2：12345&gt;&gt; C = 2*ones(2, 3)C = 2 2 2 2 2 2 高斯随机数：123456&gt;&gt; rand(3, 3)ans = 0.751588 0.906707 0.081204 0.411613 0.457779 0.882052 0.622524 0.774499 0.811092 所有元素均为0：1234&gt;&gt; w = zeros(1, 3)w = 0 0 0 单位矩阵：12345678910&gt;&gt; I = eye(5)I =Diagonal Matrix 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 读取矩阵A第三行第二列的元素：1234567A = 1 2 3 4 5 6&gt;&gt; A(3, 2)ans = 6 读取矩阵A第2列所有元素：123456&gt;&gt; A(:,2)ans = 2 4 6 读取矩阵A第2行所有元素：1234&gt;&gt; A(2,:)ans = 3 4 读取矩阵A第1行和第3行的所有元素：12345&gt;&gt; A([1 3],:)ans = 1 2 5 6 将A第二列替换为[10;11;12]：123456&gt;&gt; A(:,2) = [10; 11; 12]A = 1 10 3 11 5 12 在A的最后加上一列：123456&gt;&gt; A = [A, [100; 101; 102]]A = 1 10 100 3 11 101 5 12 102 将A所有的元素合并成一个列向量:123456789101112&gt;&gt; A(:)ans = 1 3 5 10 11 12 100 101 102 两个矩阵的合并（列合并）:1234567891011121314151617181920&gt;&gt; A = [1 2; 3 4; 5 6]A = 1 2 3 4 5 6&gt;&gt; B = [7 8; 9 10; 11 12]B = 7 8 9 10 11 12&gt;&gt; C = [A B]C = 1 2 7 8 3 4 9 10 5 6 11 12 两个矩阵的合并（行合并）:123456789&gt;&gt; D = [A;B]D = 1 2 3 4 5 6 7 8 9 10 11 12 杂项构造10000个随机数，并绘制出图形(高斯分布)：12&gt;&gt; w=randn(1,10000);&gt;&gt; hist(w,50) 数据的读取和存储 本节所用到的数据: featuresX.dat, priceY.dat 读取数据12345% 找到文件所在目录：&gt;&gt; cd Desktop/&gt;&gt; cd &apos;Machine Learning/&apos;&gt;&gt; lsfeaturesX.dat priceY.dat 数据如下所示：读取数据：123456% 方式一：&gt;&gt; load featuresX.dat&gt;&gt; load priceY.dat% 方式二：&gt;&gt; load(&apos;featuresX.dat&apos;)&gt;&gt; load(&apos;priceY.dat&apos;) 使用who命令显示当前所有变量：123456&gt;&gt; whoVariables in the current scope:A a featuresX v yC ans priceY wI c sz x 可以看到，刚才导入的数据已经在变量featuresX和priceY中了。展示数据：1234567891011121314151617181920212223242526272829303132&gt;&gt; featuresXfeaturesX = 2104 3 1600 3 2400 3 1416 2 3000 4 1985 4 1534 3 ... ..&gt;&gt; size(featuresX)ans = 27 2&gt;&gt; priceYpriceY = 3999 3299 3690 2320 5399 2999 ...&gt;&gt; size(priceY)ans = 27 1 使用如下命令用来删除某个变量：12&gt;&gt; clear featuresX&gt;&gt; whos 存储数据假设我们现在需要取出priceY前十个数据，使用如下命令：12345678910111213&gt;&gt; v = priceY(1:10)v = 3999 3299 3690 2320 5399 2999 3149 1989 2120 2425 该如何存储这十个数据呢？使用save命令：123&gt;&gt; save hello.mat v&gt;&gt; lsfeaturesX.dat hello.mat priceY.dat 清空所有变量：123&gt;&gt; clear&gt;&gt; whos&gt;&gt; %无任何输出 刚才存储数据是以二进制的形式进行存储，我们也可以使用人能够读懂的形式存储。例如：123456789101112131415161718192021222324252627&gt;&gt; load hello.mat&gt;&gt; whosVariables in the current scope: Attr Name Size Bytes Class ==== ==== ==== ===== ===== v 10x1 80 doubleTotal is 10 elements using 80 bytes&gt;&gt; vv = 3999 3299 3690 2320 5399 2999 3149 1989 2120 2425&gt;&gt; save hello.txt v -ascii&gt;&gt; lsfeaturesX.dat hello.mat hello.txt priceY.dat 数据计算12345678% 各种矩阵运算&gt;&gt; A * B&gt;&gt; A .* B&gt;&gt; A .^ 2&gt;&gt; 1 ./ A&gt;&gt; log(A)&gt;&gt; exp(A)&gt;&gt; -A A中的每个元素都加上1：1&gt;&gt; A + ones(size(A)) 这样也可以：1&gt;&gt; A + 1 矩阵转置：1&gt;&gt; A&apos; 向量中的最大值：12345678&gt;&gt; A = [1 3 0.5 10 100]A = 1.00000 3.00000 0.50000 10.00000 100.00000&gt;&gt; [val ind] = max(A)val = 100ind = 5 比较大小：12345678910111213&gt;&gt; A = [1 2; 3 4; 5 6]A = 1 2 3 4 5 6&gt;&gt; A &gt; 3ans = 0 0 0 1 1 1 找出向量中特定元素：123456&gt;&gt; find(A &gt; 3)ans = 3 5 6 找出矩阵中特定元素：1234567891011121314&gt;&gt; [r c] = find(A &gt;= 3)r = 2 3 2 3c = 1 1 2 2 生成任意行、列、对角线和相等的矩阵：123456&gt;&gt; magic(3)ans = 8 1 6 3 5 7 4 9 2 向量所有元素的和：1234567&gt;&gt; a = [1.2 2.3 4.5 6.6]a = 1.2000 2.3000 4.5000 6.6000&gt;&gt; sum(a)ans = 14.600 向上及向下取整：123456789&gt;&gt; floor(a)ans = 1 2 4 6&gt;&gt; ceil(a)ans = 2 3 5 7 构造一个由A,B两个矩阵中对应位置较大的数组成的矩阵：12345678910111213141516171819202122232425A = 1 2 3 4 5 6&gt;&gt; B = [3 1; 4 6; 2 9]B = 3 1 4 6 2 9&gt;&gt; max(A, B)ans = 3 2 4 6 5 9A = 1 2 3 4 5 6 取出矩阵每列最大的元素：1234&gt;&gt; max(A, [], 1)ans = 5 6 取出矩阵每行最大的元素：123456&gt;&gt; max(A, [], 2)ans = 2 4 6 想要直接获得矩阵中最大的元素，以下两种方式都可以：123456% 方式一：&gt;&gt; max(max(A))ans = 6% 方式二：&gt;&gt; max(A(:))ans = 6 矩阵的上下翻转：1234567891011121314151617&gt;&gt; eye(3)ans =Diagonal Matrix 1 0 0 0 1 0 0 0 1&gt;&gt; flipud(eye(3))ans =Permutation Matrix 0 0 1 0 1 0 1 0 0 矩阵的逆：1234567891011121314151617181920&gt;&gt; A = rand(3, 3)A = 0.68934 0.12881 0.80507 0.49777 0.41907 0.37271 0.32607 0.27877 0.41814&gt;&gt; tmp = pinv(A)tmp = 1.795801 4.294380 -7.285421 -2.180466 0.647802 3.620828 0.053345 -3.780710 5.658801&gt;&gt; tmp * Aans = 1.00000 0.00000 0.00000 0.00000 1.00000 0.00000 -0.00000 -0.00000 1.00000 绘制数据绘制出sin函数图像：123x = [0: 0.01: 0.98];&gt;&gt; y = sin(2*pi*4*x);&gt;&gt; plot(x,y); 绘制出cos函数图像:1y2 = cos(2*pi*4*x); 将两个函数绘制在一起：123&gt;&gt; plot(x,y);&gt;&gt; hold on;&gt;&gt; plot(x,y2,&apos;r&apos;) 添加说明：12345&gt;&gt; xlabel(&quot;time&quot;);&gt;&gt; ylabel(&quot;value&quot;);&gt;&gt; lengend(&quot;sin&quot;, &quot;cos&quot;);error: &apos;lengend&apos; undefined near line 1 column 1&gt;&gt; legend(&quot;sin&quot;, &quot;cos&quot;); 存储图像：1&gt;&gt; print -dpng &quot;myPlot.png&quot; 关掉绘制的图像：1&gt;&gt; close 分别在两个窗口显示两个图像：12&gt;&gt; figure(1); plot(x, y);&gt;&gt; figure(2); plot(x, y2); 改变左边图像的横坐标的刻度：12&gt;&gt; subplot(1,2,1)&gt;&gt; axis([0 0.5 -1 1]) 清除所有绘制的图像：1&gt;&gt; clf 将矩阵可视化：1&gt;&gt; imagesc(magic(15)) 1&gt;&gt; imagesc(A), colorbar, colormap gray 控制语句for循环：1234567&gt;&gt; for i=1:10,&gt; v(i) = i^2;&gt; end;&gt;&gt; vv = 1 4 9 16 25 36 49 64 81 100 while循环：1234567891011&gt;&gt; i = 1;&gt;&gt; while i &lt;= 10,&gt; v(i) = sqrt(v(i));&gt;Display all 1753 possibilities? (y or n)&gt; i = i + 1;&gt; end;&gt;&gt; vv = 1 2 3 4 5 6 7 8 9 10 定义一个函数：123456&gt;&gt; lsfeaturesX.dat myPlot.png squareThisNumber.mhello.mat octave-workspacehello.txt priceY.dat&gt;&gt; squareThisNumber(3)ans = 9 如果该定义的函数不在当前目录下，我们就不能使用它：12345&gt;&gt; cd ~&gt;&gt; pwdans = /Users/bobo&gt;&gt; squareThisNumber(3)error: &apos;squareThisNumber&apos; undefined near line 1 column 1 不过我们也可以更改Octave的搜索路径：1&gt;&gt; addpath(&quot;~/Desktop/Machine-Learning&quot;) 更改之后，我们现在虽然在/User/bobo目录下，但是仍然可以使用squareThisNumber函数:1234&gt;&gt; pwdans = /Users/bobo&gt;&gt; squareThisNumber(5)ans = 25 返回两个值的函数：123&gt;&gt; [y1, y2] = squareAndCube(3)y1 = 9y2 = 27 代价函数：12345678910111213141516171819202122&gt;&gt; X = [1 1; 1 2; 1 3]X = 1 1 1 2 1 3&gt;&gt; y = [1; 2; 3]y = 1 2 3&gt;&gt; theta = [0; 1]theta = 0 1&gt;&gt; costFunctionJ(X, y, theta)ans = 0 如果$\\theta=[0; 0]$12345678&gt;&gt; theta = [0; 0]theta = 0 0&gt;&gt; costFunctionJ(X, y, theta)ans = 2.3333 向量化点击这里–&gt;","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[{"name":"machinelearning","slug":"machinelearning","permalink":"http://yoursite.com/tags/machinelearning/"},{"name":"math","slug":"math","permalink":"http://yoursite.com/tags/math/"},{"name":"note","slug":"note","permalink":"http://yoursite.com/tags/note/"},{"name":"Octave","slug":"Octave","permalink":"http://yoursite.com/tags/Octave/"}]},{"title":"Coursera机器学习笔记(三) - 多变量线性回归","slug":"machine_learning_note_03","date":"2018-09-06T07:04:35.958Z","updated":"2018-09-06T15:51:33.043Z","comments":true,"path":"2018/09/06/machine_learning_note_03/","link":"","permalink":"http://yoursite.com/2018/09/06/machine_learning_note_03/","excerpt":"MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} }); 课程地址：Linear Regression with Multiple Variables课程Wiki：Linear Regression with Multiple Variables 1. 假设函数 梯度下降1.1 假设函数在之前的单变量线性回归中, 我们的问题只涉及到了房子面积这一个特征:","text":"MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} }); 课程地址：Linear Regression with Multiple Variables课程Wiki：Linear Regression with Multiple Variables 1. 假设函数 梯度下降1.1 假设函数在之前的单变量线性回归中, 我们的问题只涉及到了房子面积这一个特征: 在实际问题中, 会有很多特征. 例如, 除了房子面积, 还有房子的卧室数量$x_2$，房子的楼层数$x_3$，房子建筑年龄$x_4$，其中$n$表示特征的数量，$m$表示训练样例的数量，$x^{(i)}$表示第$i$个训练样例，$x_j^{(i)}$表示第$i$个训练样例的第$j$个特征。在单变量线性回归中假设函数为:$${h_\\theta(x)=\\theta_0+\\theta_1x}$$类似地, 现在假设函数记作：$${h_\\theta(x)=\\theta_0+\\theta_1x_1+\\theta_2x_2+…+\\theta_nx_n}$$可是每次这样写太麻烦了, 为了方便首先定义$x_0=1$（即$x_0^{(i)}=1$），此时$x_0^{(i)}=1$为：$${h_\\theta(x)=\\theta_0x_0+\\theta_1x_1+\\theta_2x_2+…+\\theta_nx_n}$$再令${\\qquad\\qquad\\theta=\\begin{bmatrix}\\theta_0\\ \\theta_1\\ \\theta_2\\.\\.\\.\\ \\theta_n \\end{bmatrix}\\in \\rm I!R^{n+1}\\quad,\\qquad\\qquad}$ ${x=\\begin{bmatrix}x_0\\x_1\\x_2\\.\\.\\.\\x_n \\end{bmatrix}\\in \\rm I!R^{n+1}}$这样就得到了假设函数的向量表示:$${h_\\theta(x)=\\theta_0x_0+\\theta_1x_1+\\theta_2x_2+…+\\theta_nx_n= \\theta^Tx}$$ 1.2 梯度下降多变量情况下的梯度下降其实没有区别, 只需要把对应的偏导数项换掉即可。 2. 特征处理2.1 特征缩放如果每个特征的范围相差的很大, 梯度下降会很慢. 为了解决这个问题, 我们在梯度下降之前应该对数据做特征归缩放(Feature Scaling)处理，从而将所有的特征的数量级都在一个差不多的范围之内, 以加快梯度下降的速度。假设现在我们有两个特征, 房子的面积和房间的数量. 如下图所示, 他们的范围相差的非常大. 对于这样的数据, 它的代价函数大概如下图左边, 梯度下降要经过很多很多次的迭代才能达到最优点. 如果我们对这两个特征按照右边给出的公式进行特征缩放, 那么此时的代价函数如下图右边所示, 相对于之前, 可以大大减少梯度下降的迭代次数。通常我们需要把特征都缩放到$[-1,1]$（附近）这个范围。 2.2 均值归一化还有一个特征处理的方法就是均值归一化(Mean normalization):$${x_i=\\frac{x_i-\\mu_i}{max-min}}$$或者$${x_i=\\frac{x_i-\\mu_i}{\\sigma_i}}$$ 3. 代价函数和学习率我们可以通过画出$\\mathop{min}\\limits_{\\theta}J(\\theta)$与迭代次数数的关系图来观察梯度下降的运行. 如下图所示, 横坐标是迭代次数, 纵坐标是代价函数的值. 如果梯度算法正常运行的话, 代价函数的图像大概的形状如下图所示。还有一种叫自动收敛测试的方法, 即每次迭代之后观察$J(\\theta)$，的值, 如果迭代之后下降的值小于$\\epsilon$（例如$\\epsilon=10^{-3}$），就判定为收敛. 不过准确地选择阈值$\\epsilon$是非常困难的，通常还是使用画图的方法。如果出现了下面的两种情况, 这个时候应该选择更小的$\\alpha$，注意: 1.$\\alpha$足够小, 那么$J(\\theta)$在每次迭代之后都会减小；2.但是如果太小, 梯度下降会进行的非常缓慢。可以使用下面几个值进行尝试 4. 特征选择和多项式回归假设预测房屋价格, 选取房屋的长和宽作为变量, 得到如下的假设函数：$$h(\\theta)=\\theta_0+\\theta_1\\times frontage+\\theta_1\\times depth$$当然, 我们觉得真正决定房屋价格应该是与房屋的面积有关. 这时候我们也可以重新选择我们的特征$x=frontage\\times depth$，此时的假设函数为：$$h(\\theta)=\\theta_0+\\theta_1x$$通过这种特征的选择, 我们可能得到一个更好的模型和这个密切相关的一个概念就是多项式回归(Polynomial Regression). 假设有下图所示的关于房屋价格的数据集, 我们有多种模型去拟合(下图右所示). 第一个模型是一个二次函数, 但是二次函数是一个抛物线, 这里不符合(因为房价不会随着房子面积的增加二减小)；所以我们选择三次函数的模型, 想要使用该模型去拟合. 那么我们该如何将这个模型运用在我们的数据上呢？我们可以将房屋的面积作为第一个特征, 面积的平方作为第二个特征, 面积的立方作为第三个特征, 如下图左下角所示. (这里需要注意的是, $x_0,x_1,x_2$的范围差别会非常大, 所以一定要进行特征缩放处理）除了三次函数模型, 这里也可以选择平方根函数模型, 如下图所示 5. 正规方程5.1 正规方程之前我们一直是用的梯度下降求解最优值. 它的缺点就是需要进行很多次迭代才能得到全局最优解. 有没有更好的方法呢? 我们先来看一个最简单的例子, 假设现在的代价函数为$J(\\theta)=a\\theta^2+b\\theta+c$，$\\theta$是一个实数. 怎样得到最优解? 很简单, 只要令它的导数为0就可以了。事实上, 代价函数不会像例子那样简单, $\\theta$也不是一个实数，而是一个$n+1$维的向量，这样, 我们分别对每个$\\theta$求偏导，再令偏导等于0, 可以计算出左右的$\\theta$，了. 但看上去还是很繁琐, 所以下面我们介绍一种向量化的求解方法。首先, 在数据集前加上一列$x_0$，值都为1；然后将所有的变量都放入矩阵$X$中(包括加上的$x_0$)；再将输出值放入向量$y$中。最后通过公式$\\theta=(X^TX)^{-1}X^Ty$，就可以算出$\\theta$的值。下图是一个更通用的表达方式：在Octave中, 可用如下命令计算:1pinv(x&apos;*x)*x&apos;*y 这个公式叫做正规方程, 使用这种方法还有一个好处就是不需要进行特征缩放处理。 5.2 梯度下降与正规方程的比较下图是梯度下降(Gradient Descent)和正规方程(Normal Equation)两种方法优缺点的比较：梯度下降 | 正规方程 | -需要选择学习率$\\alpha$ | 不需要选择学习率$\\alpha$需要很多次迭代 | 不需要迭代当有大量特征时, 也能正常工作 | 需要计算$(X^TX)^{-1}$$O(n^3)$， n非常大时, 计算非常慢 5.3 正规方程不可逆的情况使用正规方程还有一个问题就是$X^TX$可能存在不可逆的情况。这个时候, 可能是因为我们使用了冗余的特征, 还有一个原因是我们使用了太多的特征(特征的数量超过了样本的数量)。对于这种情况我们可以删掉一些特征或者使用正则化(正则化在后面的课中讲)。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[{"name":"machinelearning","slug":"machinelearning","permalink":"http://yoursite.com/tags/machinelearning/"},{"name":"math","slug":"math","permalink":"http://yoursite.com/tags/math/"},{"name":"note","slug":"note","permalink":"http://yoursite.com/tags/note/"}]},{"title":"《极恶非道》观后感","slug":"jiefeidao_comment","date":"2018-09-05T14:18:06.603Z","updated":"2018-09-05T14:18:06.603Z","comments":true,"path":"2018/09/05/jiefeidao_comment/","link":"","permalink":"http://yoursite.com/2018/09/05/jiefeidao_comment/","excerpt":"无关乎生存，仅在乎利益。这是电影交代的黑帮从上而下的恶，这种恶充斥了整部电影，不仅黑帮，也有警察。 北野武是以拍摄黑帮片出道，早期的《奏鸣曲》是一部故事完全发生黑帮内部的电影，但北野武没有把电影拍成类型化的模式，而是嚼碎了各种类型化的元素，为之注入了他个人独特的对于荒诞生命的严峻思考。2000年赴美拍摄的《大佬》倒是比较类型化，影片不断展示帮派战斗的过程，还充满了东西方文化的差异比较，生死相托的日式侠义精神在影片中被反复讴歌。","text":"无关乎生存，仅在乎利益。这是电影交代的黑帮从上而下的恶，这种恶充斥了整部电影，不仅黑帮，也有警察。 北野武是以拍摄黑帮片出道，早期的《奏鸣曲》是一部故事完全发生黑帮内部的电影，但北野武没有把电影拍成类型化的模式，而是嚼碎了各种类型化的元素，为之注入了他个人独特的对于荒诞生命的严峻思考。2000年赴美拍摄的《大佬》倒是比较类型化，影片不断展示帮派战斗的过程，还充满了东西方文化的差异比较，生死相托的日式侠义精神在影片中被反复讴歌。《极恶非道》是北野武十年后回归暴力黑社会的作品。影片的叙事法则便是你来我往的夺权战斗。叙事出发点始于关内会长（北村总一朗 扮）要抢夺村濑（石桥莲司 扮）组的地盘，用的策略是并不高明的挑拨离间，让曾经与村濑为狱友的池元（国村隼 扮）与之大战。池元手下的大友（北野武 扮）组与村濑组的木村（中野英雄 扮）也随之展开斗争。这是一部众生相电影，与之相关的重要角色还有大友组的石原（加濑亮 扮）、水野（椎名桔平 扮），会长手下的加藤（三浦友和 扮），负责暴力团事物的警察片冈。影片的日文片名直译是《全员恶人》，这里面确实没有一个道德方面的善良之辈，没有英雄，只有恶人。尤其是几个首领，关内会长、池元、村濑，没有任何道义和领袖魅力可言，有的只是利欲熏心。过往日本黑帮组织的一些情义亦是荡然无存。池元与村濑本来是狱友，在《无仁义之战》第一集中，狱友曾经是被表现为敢用性命相托的赤胆忠诚之关系，在本片中却是一文不值，面对质问，池元甚至说，“拜把只是个仪式”。木村连切手指都不敢。而当大友当真用切手指的方法道歉时，却被会长讥讽这过时了，“老套的切手指没有用”。在此特别值得一提的是北野扮演的大友这个角色，正是这个角色的存在为这部黑帮片注入了一些别样的独属于北野武式思考的活力。 大友在影片虽亦是热衷暴力的恶人，但在道义上却是偏向正面。他当真视池元为干爹，为其卖命，但随后看透了这套把戏之后，意识到这是一场你死我活的战斗。黑帮中人，本来已经看透生死，当意识到道之不存后，大友便将这场战斗看成了无关道义的死亡游戏。死亡到来的时刻便是当下澄明的解脱时刻，这是北野武式洒脱豁达当下即是的生命哲学。正是这个视点又为这部类型化程度很高的黑帮电影，注入了一种抽离的客观化的视点。也正是在北野武独特生命哲学的关照之下，与死亡密切相关的暴力，被北野武表达的如此极致。北野武多年来的采访中曾多次表达了个人对暴力的看法，他讨厌美感的暴力，他认为暴力的本质就是伤痛，“暴力就是暴力，我希望用暴力的镜头刺痛观众，让他们知道暴力有多么糟糕，所以我不会顾忌该用什么样的方式，用多野蛮的力度。也许你们看电影的时候，已经觉得承受不了了，但其实这是我故意制造出来的，我希望让观众感到剧烈的疼痛和恐惧，这种感觉就是暴力的本质。我最讨厌那种把暴力拍得很美的电影，还冠以暴力美学的美称，那样的电影才是教坏小孩子的罪魁祸首”。吴宇森式的自我崇高化的浪漫暴力，或者塔伦蒂诺式卡通恶趣味暴力，在北野武的电影中是看不到的。瞬间爆发的，极致的，带来无比伤痛的暴力才是真正的北野暴力。在《极恶非道》系列中，北野勾画出的暴力类型亦是极端残酷：电钻凿牙齿、筷子猛插耳朵、猛击舌头导致卡舌而死、棒球连续性地击砸面门。最汹涌澎湃的无情暴力莫过于与大友并肩作战到最后的水野：头颅被绳子套住后飞车拉断而死。 《极恶非道》系列第二集的主题与叙事模式与第一集类似，只是权斗的始作俑者变成了警察片冈。警方这套挑拨离间以暴易暴的制敌模式也是其来有自。1987年，一和会与山口组发生了激烈的暴力抗争。当时，一合会打算在大阪地区刺杀新上任的山口组组长竹中正久，他们用了二十多部无线电对讲机。关西电信局发现情况后报警，但警方不予理睬，为的就是帮助一合会行刺，以暴易暴。不过片冈在影片中并非正义人士，而是猥琐的敲诈犯，当大友看破这死局后，二话不说一枪击毙片冈。影片的高潮来得猝不及防，但却酣畅淋漓，激越又超然。 这是一部非常纯正的yakuza电影，而电影中表现的暴力和深作欣二的热血翻滚不同，北野武的暴力凝固至冰点，让人看完脊背发凉。 最激烈的暴力与死亡冲动同样可以是最深邃的生命顿悟。","categories":[{"name":"影评","slug":"影评","permalink":"http://yoursite.com/categories/影评/"}],"tags":[{"name":"北野武","slug":"北野武","permalink":"http://yoursite.com/tags/北野武/"},{"name":"yakuza","slug":"yakuza","permalink":"http://yoursite.com/tags/yakuza/"}]},{"title":"Coursera机器学习笔记(二) - 单变量线性回归(补充 - 梯度下降算法)","slug":"machine_learning_note_02_addition","date":"2018-09-05T13:51:57.176Z","updated":"2018-09-05T13:53:58.677Z","comments":true,"path":"2018/09/05/machine_learning_note_02_addition/","link":"","permalink":"http://yoursite.com/2018/09/05/machine_learning_note_02_addition/","excerpt":"MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} }); 梯度下降梯度下降算法是一种优化算法, 它可以帮助我们找到一个函数的局部极小值点. 它不仅仅可以用在线性回归模型中, 在机器学习许多其他的模型中也可以使用它. 对于我们现在研究的单变量线性回归来说, 我们想要使用梯度下降来找到最优的$\\theta_0$、$\\theta_1$。它的思想是, 首先随机选择两个$\\theta_0$、$\\theta_1$，不断地改变它们的值使得$J(\\theta_0,\\theta_1)$变小，最终找到$J(\\theta_0,\\theta_1)$的最小值。","text":"MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} }); 梯度下降梯度下降算法是一种优化算法, 它可以帮助我们找到一个函数的局部极小值点. 它不仅仅可以用在线性回归模型中, 在机器学习许多其他的模型中也可以使用它. 对于我们现在研究的单变量线性回归来说, 我们想要使用梯度下降来找到最优的$\\theta_0$、$\\theta_1$。它的思想是, 首先随机选择两个$\\theta_0$、$\\theta_1$，不断地改变它们的值使得$J(\\theta_0,\\theta_1)$变小，最终找到$J(\\theta_0,\\theta_1)$的最小值。 可以把梯度下降的过程想象成下山坡, 如果想要尽可能快的下坡, 应该每次都往坡度最大的方向下山。梯度下降算法得到的结果会受到初始状态的影响, 即当从不同的点开始时, 可能到达不同的局部极小值, 如下图:下面具体看一下算法的过程, 如下图所示, 其中$:=$表示赋值，$\\alpha$表示学习率用来控制下降的幅度，$\\frac{\\partial}{\\partial\\theta_j}J(\\theta_0, \\theta_1)$表示梯度。这里一定要注意的是，算法每次是同时(simultaneously)改变$\\theta_0$和$\\theta_1$的值，如下图所示 梯度和学习率我们先来看看梯度下降算法的梯度是如何帮助我们找到最优解的. 为了研究问题的方便我们还是同样地令$\\theta_0=0$，假设一开始选取的$\\theta_1$在最低点右侧，此时的梯度(斜率)是一个正数。根据上面的算法更新$\\theta_1$的时候，它的值会减小, 即靠近最低点。类似地假设一开始选取的$\\theta_1$在最低点的左侧，此时的梯度是一个负数，根据上面的算法更新$\\theta_1$的时候，它的值会增大，也会靠近最低点。如果一开始选取的$\\theta_1$恰好在最适位置，那么更新$\\theta_1$时，它的值不会发生变化。学习率$\\alpha$会影响梯度下降的幅度。如果$\\alpha$太小，$\\theta$的值每次会变化的很小，那么梯度下降就会非常慢；相反地，如果$\\alpha$太大，$\\theta$的值每次会变化的很大，有可能直接越过最低点，可能导致永远没法到达最低点。由于随着越来越接近最低点, 相应的梯度(绝对值)也会逐渐减小，所以每次下降程度就会越来越小, 我们并不需要减小$\\alpha$的值来减小下降程度。 计算梯度根据定义, 梯度也就是代价函数对每个$\\theta$求偏导：我们将$h_\\theta(x^{(i)})=\\theta_0+\\theta_1x^{(i)}$带入到$J(\\theta_0,\\theta_1)$中，并且分别对$\\theta_0$，$\\theta_1$求导得：由此得到了完整的梯度下降算法:前面说了梯度下降算法得到的结果会受初始状态的影响, 即初始状态不同, 结果可能是不同的局部最低点。事实上，用于线性回归的代价函数总是一个凸函数(Convex Function)。这样的函数没有局部最优解，只有一个全局最优解。所以我们在使用梯度下降的时候，总会得到一个全局最优解。下面我们来看一下梯度下降的运行过程：迭代多次后，我们得到了最优解。现在我们可以用最优解对应的假设函数来对房价进行预测了。例如一个1,250平方英尺的房子大概能卖到250k$，如下图所示：","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[{"name":"machinelearning","slug":"machinelearning","permalink":"http://yoursite.com/tags/machinelearning/"},{"name":"math","slug":"math","permalink":"http://yoursite.com/tags/math/"},{"name":"note","slug":"note","permalink":"http://yoursite.com/tags/note/"}]},{"title":"Coursera机器学习笔记(二) - 单变量线性回归","slug":"machine_learning_note_02","date":"2018-09-04T14:27:55.458Z","updated":"2018-09-05T14:01:00.986Z","comments":true,"path":"2018/09/04/machine_learning_note_02/","link":"","permalink":"http://yoursite.com/2018/09/04/machine_learning_note_02/","excerpt":"MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} }); 课程地址：Linear Regression with One Variable课程Wiki：Linear Regression with One Variable 1. 基本概念1.1 训练集由训练样例(training example)组成的集合就是训练集(training set)，如下图所示, 其中$(x, y)$是一个训练样例, $(x^{(i)}, y^{(i)})$第i个训练样例。","text":"MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]} }); 课程地址：Linear Regression with One Variable课程Wiki：Linear Regression with One Variable 1. 基本概念1.1 训练集由训练样例(training example)组成的集合就是训练集(training set)，如下图所示, 其中$(x, y)$是一个训练样例, $(x^{(i)}, y^{(i)})$第i个训练样例。 1.2 假设函数使用某种学习算法对训练集的数据进行训练, 我们可以得到假设函数(Hypothesis Function), 如下图所示. 在房价的例子中，假设函数就是一个房价关于房子面积的函数。有了这个假设函数之后, 给定一个房子的面积我们就可以预测它的价格了。我们使用如下的形式表示假设函数, 为了方便，$h_\\theta(x)$也可以记作$h(x)$$${h_\\theta(x)=\\theta_0+\\theta_1x}$$以上这个模型就叫做单变量的线性回归(Linear Regression with One Variable). (Linear regression with one variable = Univariate linear regression，univariate是one variable的装逼写法。) 2. 代价函数2.1 什么是代价函数只要我们知道了假设函数, 我们就可以进行预测了. 关键是, 假设函数中有两个未知的量$\\theta_0, \\theta_1$，当选择不同的$\\theta_0$和$\\theta_1$时，我们模型的效果肯定是不一样的。如下图所示, 列举了三种不同的$\\theta_0$和$\\theta_1$下的假设函数。现在的问题就是该如何选择这两个参数了。我们的想法是选择某个$\\theta_0$和$\\theta_1$，使得对于训练样例$(x,y)$，$h_\\theta(x)$最接近$y$。越是接近, 代表这个假设函数越是准确, 这里我们选择均方误差来作为衡量标准, 即我们想要每个样例的估计值与真实值之间差的平方的均值最小。用公式表达为:$${\\mathop{minimize}\\limits_{\\theta_0,\\theta_1} \\frac{1}{2m}\\sum_{i=0}^m\\left(h_\\theta(x^{(i)})-y^{(i)}\\right)^2}$$（其中$1/2$是为了后面方便计算）我们记$${J(\\theta_0,\\theta_1)=\\frac{1}{2m}\\sum_{i=0}^m\\left(h_\\theta(x^{(i)})-y^{(i)}\\right)^2}$$这样就得到了我们的代价函数(cost function), 也就是我们的优化目标, 我们想要代价函数最小:$$\\mathop{minimize}\\limits_{\\theta_0,\\theta_1}J(\\theta_0,\\theta_1)$$ 2.2 代价函数和假设函数现在为了更方便地探究$h_\\theta(x)$和$J(\\theta_0,\\theta_1)$的关系，先令$\\theta_0=0$，得到了简化后的假设函数，有假设函数的定义可知此时的假设函数是经过原点的直线. 相应地也也得到简化的代价函数。如图所示:简化之后，我们令$\\theta_1=1$，就得到$h_\\theta(x)=x$，如下图左所示。图中三个红叉表示训练样例，通过代价函数的定义我们计算得出$J(1)=0$，对应下图右中的$(0,1)$坐标重复上面的步骤，再令$\\theta_1=0.5$，得到$h_\\theta(x)$如下图左所示。通过计算得出$J(0.5)=0.58$，对应下图右中的$(0.5,0.58)$对于不同的$\\theta_1$，对应着不同的假设函数$h_\\theta(x)$，于是就有了不同的$J(\\theta_1)$。将这些点连接起来就可以得到$J(\\theta_1)$关于$\\theta_1$的函数图像，如下图所示：我们的目标就是找到一个$\\theta$使得$J(\\theta)$最小，通过上面的描点作图的方式, 我们可以从图中看出, 当$\\theta=1$的时候，$J(\\theta)$取到最小值。 2.3 代价函数与假设函数II在上一节中，我们令$\\theta_0=0$，并且通过设置不同的$\\theta_1$来描点作图得到$J(\\theta_1)$的曲线。这一节我们不再令$\\theta_0=0$，而是同时设置$\\theta_0$和$\\theta_1$的值，然后再绘出$J(\\theta_0, \\theta_1)$的图形。因为此时有两个变量，很容易想到$J(\\theta_0, \\theta_1)$应该是一个曲面, 如下图所示:这个图是教授用matlab绘制的，由于3D图形不太方便我们研究，我们就使用二维的等高线(上图右上角教授写的contour plots/figures)，这样看上去比较清楚一些。如下图右，越靠近中心表示$J(\\theta_0, \\theta_1)$的值越小(对应3D图中越靠近最低点的位置)。下图左表示当$\\theta_0=800$，$\\theta_1=0.15$的时候对应的$h_\\theta(x)$，通过$\\theta_0$和$\\theta_1$的值可以找到下图右中$J(\\theta_0, \\theta_1)$的值。类似地：我们不断尝试直到找到一个最佳的$h_\\theta(x)$。是否有特定的算法能帮助我们找到最佳的$h_\\theta(x)$呢？下面我们就要介绍这个算法-梯度下降算法。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[{"name":"machinelearning","slug":"machinelearning","permalink":"http://yoursite.com/tags/machinelearning/"},{"name":"math","slug":"math","permalink":"http://yoursite.com/tags/math/"},{"name":"note","slug":"note","permalink":"http://yoursite.com/tags/note/"}]},{"title":"Coursera机器学习笔记(一) - 监督学习vs无监督学习","slug":"machine_learning_note_01","date":"2018-09-04T14:03:23.953Z","updated":"2018-09-06T04:55:55.476Z","comments":true,"path":"2018/09/04/machine_learning_note_01/","link":"","permalink":"http://yoursite.com/2018/09/04/machine_learning_note_01/","excerpt":"课程地址：Supervised Learning &amp; Unsupervised Learning课程Wiki：Introduction 1. 监督学习什么是监督学习? 我们来看看维基百科中给出的定义: 监督式学习（英语：Supervised learning），是一个机器学习中的方法，可以由训练资料中学到或建立一个模式（函数 / learning model），并依此模式推测新的实例。训练资料是由输入物件（通常是向量）和预期输出所组成。函数的输出可以是一个连续的值（称为回归分析），或是预测一个分类标签（称作分类） 从数据的角度来讲, 监督学习和无监督学习的区别就在于监督学习的数据不仅仅有特征组成, 即每一个数据样本都包含一个准确的输出值. 在房价预测的问题中, 数据由特征+房价组成。","text":"课程地址：Supervised Learning &amp; Unsupervised Learning课程Wiki：Introduction 1. 监督学习什么是监督学习? 我们来看看维基百科中给出的定义: 监督式学习（英语：Supervised learning），是一个机器学习中的方法，可以由训练资料中学到或建立一个模式（函数 / learning model），并依此模式推测新的实例。训练资料是由输入物件（通常是向量）和预期输出所组成。函数的输出可以是一个连续的值（称为回归分析），或是预测一个分类标签（称作分类） 从数据的角度来讲, 监督学习和无监督学习的区别就在于监督学习的数据不仅仅有特征组成, 即每一个数据样本都包含一个准确的输出值. 在房价预测的问题中, 数据由特征+房价组成。 1.1 监督学习的分类在监督学习中, 我们的预测结果可以是连续值, 也可以是离散值。我们根据这样的属性将监督学习分为回归问题和分类问题。下面我们分别举一个例子来看看, 学完这两个例子之后, 我们就会对监督学习, 回归以及分类有比较清晰地认识了。 1.2 监督学习举例1.2.1 回归问题我们现在有这么一个问题, 我们想通过给定的一个房子的面积来预测这个房子在市场中的价格。这里的房子的面积就是特征, 房子的价格就是一个输出值。为了解决这个问题, 我们获取了大量的房地产数据, 每一条数据都包含房子的面积及其对应价格. 第一, 我们的数据不仅包含房屋的面积, 还包含其对应的价格, 而我们的目标就是通过面积预测房价。所以这应该是一个监督学习; 其次, 我们的输出数据房价可以看做是连续的值, 所以这个问题是一个回归问题。至于如何通过数据得到可以使用的模型, 后面的几节课再做讨论。 1.2.2 分类问题再来看一个分类问题, 从名字上来讲, 分类问题还是比较好理解的, 我们的目标应该是要对数据进行分类。现在我们的数据是有关乳腺癌的医学数据, 它包含了肿瘤的大小以及该肿瘤是良性的还是恶性的。我们的目标是给定一个肿瘤的大小来预测它是良性还是恶性. 我们可以用0代表良性，1代表恶性。这就是一个分类问题, 因为我们要预测的是一个离散值。当然, 在这个例子中, 我们的离散值可以去’良性’或者’恶性’. 在其他分类问题中, 离散值可能会大于两个。例如在该例子中可以有{0,1,2,3}四种输出，分别对应{良性, 第一类肿瘤, 第二类肿瘤, 第三类肿瘤}。在这个例子中特征只有一个即瘤的大小。 对于大多数机器学习的问题, 特征往往有多个(上面的房价问题也是, 实际中特征不止是房子的面积)..例如下图， 有“年龄”和“肿瘤大小”两个特征。(还可以有其他许多特征，如下图右侧所示) 2. 无监督学习在监督学习中我们也提到了它与无监督学习的区别。在无监督学习中, 我们的数据并没有给出特定的标签, 例如上面例子中的房价或者是良性还是恶性。我们目标也从预测某个值或者某个分类便成了寻找数据集中特殊的或者对我们来说有价值结构。如下图所示, 我们可以直观的感受到监督学习和无监督学习在数据集上的区别。我们也可以从图中看到, 大概可以将数据及分成两个簇。将数据集分成不同簇的无监督学习算法也被称为聚类算法。 2.1 无监督学习举例2.1.1 新闻分类第一个例子举的是Google News的例子。Google News搜集网上的新闻，并且根据新闻的主题将新闻分成许多簇, 然后将在同一个簇的新闻放在一起。如图中红圈部分都是关于BP Oil Well各种新闻的链接，当打开各个新闻链接的时候，展现的都是关于BP Oil Well的新闻。 2.1.2 根据给定基因将人群分类如图是DNA数据，对于一组不同的人我们测量他们DNA中对于一个特定基因的表达程度。然后根据测量结果可以用聚类算法将他们分成不同的类型。 2.1.3 鸡尾酒排队效应详见课程: Unsupervised Learning 2.1.4 其他这里又举了其他几个例子，有组织计算机集群，社交网络分析，市场划分，天文数据分析等。具体可以看一下视频：Unsupervised Learning","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[{"name":"machinelearning","slug":"machinelearning","permalink":"http://yoursite.com/tags/machinelearning/"},{"name":"math","slug":"math","permalink":"http://yoursite.com/tags/math/"},{"name":"note","slug":"note","permalink":"http://yoursite.com/tags/note/"}]},{"title":"机器学习资料整理","slug":"machine_learning_materials","date":"2018-09-03T10:38:41.948Z","updated":"2018-09-03T11:26:46.850Z","comments":true,"path":"2018/09/03/machine_learning_materials/","link":"","permalink":"http://yoursite.com/2018/09/03/machine_learning_materials/","excerpt":"微积分&emsp;&emsp;Single Variable Calculus - MIT 线性代数&emsp;&emsp;Linear Algebra - MIT","text":"微积分&emsp;&emsp;Single Variable Calculus - MIT 线性代数&emsp;&emsp;Linear Algebra - MIT 概率论与数理统计&emsp;&emsp;(暂无) 凸优化&emsp;&emsp;(暂无) Python&emsp;&emsp;廖雪峰Python教程&emsp;&emsp;Learn python in Y minutes 机器学习&emsp;&emsp;Coursera机器学习 - Andrew Ng&emsp;&emsp;CS229 - Andrew Ng&emsp;&emsp;《统计学习方法》- 李航&emsp;&emsp;《机器学习》 - 周志华&emsp;&emsp;Udacity Machine Learning Engineer Nanodegree 深度学习&emsp;&emsp;Coursera Deep Learning Sepecialization - deeplearning.ai 自然语言系统&emsp;&emsp;(暂无) 推荐系统&emsp;&emsp;推荐系统实践 - 项亮 竞赛&emsp;&emsp;Kaggle","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[{"name":"machinelearning","slug":"machinelearning","permalink":"http://yoursite.com/tags/machinelearning/"},{"name":"deeplearning","slug":"deeplearning","permalink":"http://yoursite.com/tags/deeplearning/"},{"name":"math","slug":"math","permalink":"http://yoursite.com/tags/math/"}]},{"title":"吴恩达机器学习笔记-目录","slug":"machine_learning_note","date":"2018-09-03T09:47:33.890Z","updated":"2018-09-06T15:47:43.909Z","comments":true,"path":"2018/09/03/machine_learning_note/","link":"","permalink":"http://yoursite.com/2018/09/03/machine_learning_note/","excerpt":"","text":"持续更新中…… Coursera机器学习笔记(一) - 监督学习vs无监督学习Coursera机器学习笔记(二) - 单变量线性回归Coursera机器学习笔记(三) - 多变量线性回归Coursera机器学习笔记(四) - Octave教程","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[{"name":"machinelearning","slug":"machinelearning","permalink":"http://yoursite.com/tags/machinelearning/"},{"name":"math","slug":"math","permalink":"http://yoursite.com/tags/math/"},{"name":"note","slug":"note","permalink":"http://yoursite.com/tags/note/"}]}]}