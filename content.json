{"meta":{"title":"大山","subtitle":"这是一个热爱技术、热爱烹饪的肥宅","description":"孤高锦瑟笑游侠","author":"大山","url":"http://yoursite.com"},"pages":[{"title":"archives","date":"2018-09-01T12:19:26.000Z","updated":"2018-09-01T12:20:05.974Z","comments":true,"path":"archives/index.html","permalink":"http://yoursite.com/archives/index.html","excerpt":"","text":""},{"title":"categories","date":"2018-09-01T12:18:15.000Z","updated":"2018-09-03T11:21:03.775Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-09-01T11:22:42.000Z","updated":"2018-09-01T11:24:46.112Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Coursera机器学习笔记(一) - 监督学习vs无监督学习","slug":"machine_learning_note_01","date":"2018-09-04T14:03:23.953Z","updated":"2018-09-04T14:11:17.179Z","comments":true,"path":"2018/09/04/machine_learning_note_01/","link":"","permalink":"http://yoursite.com/2018/09/04/machine_learning_note_01/","excerpt":"&emsp;&emsp;课程地址：Supervised Learning &amp; Unsupervised Learning&emsp;&emsp;课程Wiki：Introduction 1. 监督学习什么是监督学习? 我们来看看维基百科中给出的定义: 监督式学习（英语：Supervised learning），是一个机器学习中的方法，可以由训练资料中学到或建立一个模式（函数 / learning model），并依此模式推测新的实例。训练资料是由输入物件（通常是向量）和预期输出所组成。函数的输出可以是一个连续的值（称为回归分析），或是预测一个分类标签（称作分类） 从数据的角度来讲, 监督学习和无监督学习的区别就在于监督学习的数据不仅仅有特征组成, 即每一个数据样本都包含一个准确的输出值. 在房价预测的问题中, 数据由特征+房价组成。","text":"&emsp;&emsp;课程地址：Supervised Learning &amp; Unsupervised Learning&emsp;&emsp;课程Wiki：Introduction 1. 监督学习什么是监督学习? 我们来看看维基百科中给出的定义: 监督式学习（英语：Supervised learning），是一个机器学习中的方法，可以由训练资料中学到或建立一个模式（函数 / learning model），并依此模式推测新的实例。训练资料是由输入物件（通常是向量）和预期输出所组成。函数的输出可以是一个连续的值（称为回归分析），或是预测一个分类标签（称作分类） 从数据的角度来讲, 监督学习和无监督学习的区别就在于监督学习的数据不仅仅有特征组成, 即每一个数据样本都包含一个准确的输出值. 在房价预测的问题中, 数据由特征+房价组成。 1.1 监督学习的分类在监督学习中, 我们的预测结果可以是连续值, 也可以是离散值。我们根据这样的属性将监督学习分为回归问题和分类问题。下面我们分别举一个例子来看看, 学完这两个例子之后, 我们就会对监督学习, 回归以及分类有比较清晰地认识了。 1.2 监督学习举例1.2.1 回归问题我们现在有这么一个问题, 我们想通过给定的一个房子的面积来预测这个房子在市场中的价格。这里的房子的面积就是特征, 房子的价格就是一个输出值。为了解决这个问题, 我们获取了大量的房地产数据, 每一条数据都包含房子的面积及其对应价格. 第一, 我们的数据不仅包含房屋的面积, 还包含其对应的价格, 而我们的目标就是通过面积预测房价。所以这应该是一个监督学习; 其次, 我们的输出数据房价可以看做是连续的值, 所以这个问题是一个回归问题。至于如何通过数据得到可以使用的模型, 后面的几节课再做讨论。 1.2.2 分类问题再来看一个分类问题, 从名字上来讲, 分类问题还是比较好理解的, 我们的目标应该是要对数据进行分类。现在我们的数据是有关乳腺癌的医学数据, 它包含了肿瘤的大小以及该肿瘤是良性的还是恶性的。我们的目标是给定一个肿瘤的大小来预测它是良性还是恶性. 我们可以用0代表良性，1代表恶性。这就是一个分类问题, 因为我们要预测的是一个离散值。当然, 在这个例子中, 我们的离散值可以去’良性’或者’恶性’. 在其他分类问题中, 离散值可能会大于两个。例如在该例子中可以有{0,1,2,3}四种输出，分别对应{良性, 第一类肿瘤, 第二类肿瘤, 第三类肿瘤}。在这个例子中特征只有一个即瘤的大小。 对于大多数机器学习的问题, 特征往往有多个(上面的房价问题也是, 实际中特征不止是房子的面积)..例如下图， 有“年龄”和“肿瘤大小”两个特征。(还可以有其他许多特征，如下图右侧所示) 2. 无监督学习在监督学习中我们也提到了它与无监督学习的区别。在无监督学习中, 我们的数据并没有给出特定的标签, 例如上面例子中的房价或者是良性还是恶性。我们目标也从预测某个值或者某个分类便成了寻找数据集中特殊的或者对我们来说有价值结构。如下图所示, 我们可以直观的感受到监督学习和无监督学习在数据集上的区别。我们也可以从图中看到, 大概可以将数据及分成两个簇。将数据集分成不同簇的无监督学习算法也被称为聚类算法。 2.1 无监督学习举例2.1.1 新闻分类第一个例子举的是Google News的例子。Google News搜集网上的新闻，并且根据新闻的主题将新闻分成许多簇, 然后将在同一个簇的新闻放在一起。如图中红圈部分都是关于BP Oil Well各种新闻的链接，当打开各个新闻链接的时候，展现的都是关于BP Oil Well的新闻。 2.1.2 根据给定基因将人群分类如图是DNA数据，对于一组不同的人我们测量他们DNA中对于一个特定基因的表达程度。然后根据测量结果可以用聚类算法将他们分成不同的类型。 2.1.3 鸡尾酒排队效应详见课程: Unsupervised Learning 2.1.4 其他这里又举了其他几个例子，有组织计算机集群，社交网络分析，市场划分，天文数据分析等。具体可以看一下视频：Unsupervised Learning","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[{"name":"machinelearning","slug":"machinelearning","permalink":"http://yoursite.com/tags/machinelearning/"},{"name":"math","slug":"math","permalink":"http://yoursite.com/tags/math/"},{"name":"note","slug":"note","permalink":"http://yoursite.com/tags/note/"}]},{"title":"《极恶非道》观后感","slug":"jiefeidao_comment","date":"2018-09-03T16:25:26.601Z","updated":"2018-09-03T16:30:25.364Z","comments":true,"path":"2018/09/04/jiefeidao_comment/","link":"","permalink":"http://yoursite.com/2018/09/04/jiefeidao_comment/","excerpt":"无关乎生存，仅在乎利益。这是电影交代的黑帮从上而下的恶，这种恶充斥了整部电影，不仅黑帮，也有警察。 北野武是以拍摄黑帮片出道，早期的《奏鸣曲》是一部故事完全发生黑帮内部的电影，但北野武没有把电影拍成类型化的模式，而是嚼碎了各种类型化的元素，为之注入了他个人独特的对于荒诞生命的严峻思考。2000年赴美拍摄的《大佬》倒是比较类型化，影片不断展示帮派战斗的过程，还充满了东西方文化的差异比较，生死相托的日式侠义精神在影片中被反复讴歌。","text":"无关乎生存，仅在乎利益。这是电影交代的黑帮从上而下的恶，这种恶充斥了整部电影，不仅黑帮，也有警察。 北野武是以拍摄黑帮片出道，早期的《奏鸣曲》是一部故事完全发生黑帮内部的电影，但北野武没有把电影拍成类型化的模式，而是嚼碎了各种类型化的元素，为之注入了他个人独特的对于荒诞生命的严峻思考。2000年赴美拍摄的《大佬》倒是比较类型化，影片不断展示帮派战斗的过程，还充满了东西方文化的差异比较，生死相托的日式侠义精神在影片中被反复讴歌。《极恶非道》是北野武十年后回归暴力黑社会的作品。影片的叙事法则便是你来我往的夺权战斗。叙事出发点始于关内会长（北村总一朗 扮）要抢夺村濑（石桥莲司 扮）组的地盘，用的策略是并不高明的挑拨离间，让曾经与村濑为狱友的池元（国村隼 扮）与之大战。池元手下的大友（北野武 扮）组与村濑组的木村（中野英雄 扮）也随之展开斗争。这是一部众生相电影，与之相关的重要角色还有大友组的石原（加濑亮 扮）、水野（椎名桔平 扮），会长手下的加藤（三浦友和 扮），负责暴力团事物的警察片冈。影片的日文片名直译是《全员恶人》，这里面确实没有一个道德方面的善良之辈，没有英雄，只有恶人。尤其是几个首领，关内会长、池元、村濑，没有任何道义和领袖魅力可言，有的只是利欲熏心。过往日本黑帮组织的一些情义亦是荡然无存。池元与村濑本来是狱友，在《无仁义之战》第一集中，狱友曾经是被表现为敢用性命相托的赤胆忠诚之关系，在本片中却是一文不值，面对质问，池元甚至说，“拜把只是个仪式”。木村连切手指都不敢。而当大友当真用切手指的方法道歉时，却被会长讥讽这过时了，“老套的切手指没有用”。在此特别值得一提的是北野扮演的大友这个角色，正是这个角色的存在为这部黑帮片注入了一些别样的独属于北野武式思考的活力。 大友在影片虽亦是热衷暴力的恶人，但在道义上却是偏向正面。他当真视池元为干爹，为其卖命，但随后看透了这套把戏之后，意识到这是一场你死我活的战斗。黑帮中人，本来已经看透生死，当意识到道之不存后，大友便将这场战斗看成了无关道义的死亡游戏。死亡到来的时刻便是当下澄明的解脱时刻，这是北野武式洒脱豁达当下即是的生命哲学。正是这个视点又为这部类型化程度很高的黑帮电影，注入了一种抽离的客观化的视点。也正是在北野武独特生命哲学的关照之下，与死亡密切相关的暴力，被北野武表达的如此极致。北野武多年来的采访中曾多次表达了个人对暴力的看法，他讨厌美感的暴力，他认为暴力的本质就是伤痛，“暴力就是暴力，我希望用暴力的镜头刺痛观众，让他们知道暴力有多么糟糕，所以我不会顾忌该用什么样的方式，用多野蛮的力度。也许你们看电影的时候，已经觉得承受不了了，但其实这是我故意制造出来的，我希望让观众感到剧烈的疼痛和恐惧，这种感觉就是暴力的本质。我最讨厌那种把暴力拍得很美的电影，还冠以暴力美学的美称，那样的电影才是教坏小孩子的罪魁祸首”。吴宇森式的自我崇高化的浪漫暴力，或者塔伦蒂诺式卡通恶趣味暴力，在北野武的电影中是看不到的。瞬间爆发的，极致的，带来无比伤痛的暴力才是真正的北野暴力。在《极恶非道》系列中，北野勾画出的暴力类型亦是极端残酷：电钻凿牙齿、筷子猛插耳朵、猛击舌头导致卡舌而死、棒球连续性地击砸面门。最汹涌澎湃的无情暴力莫过于与大友并肩作战到最后的水野：头颅被绳子套住后飞车拉断而死。 《极恶非道》系列第二集的主题与叙事模式与第一集类似，只是权斗的始作俑者变成了警察片冈。警方这套挑拨离间以暴易暴的制敌模式也是其来有自。1987年，一和会与山口组发生了激烈的暴力抗争。当时，一合会打算在大阪地区刺杀新上任的山口组组长竹中正久，他们用了二十多部无线电对讲机。关西电信局发现情况后报警，但警方不予理睬，为的就是帮助一合会行刺，以暴易暴。不过片冈在影片中并非正义人士，而是猥琐的敲诈犯，当大友看破这死局后，二话不说一枪击毙片冈。影片的高潮来得猝不及防，但却酣畅淋漓，激越又超然。 这是一部非常纯正的yakuza电影，而电影中表现的暴力和深作欣二的热血翻滚不同，北野武的暴力凝固至冰点，让人看完脊背发凉。 最激烈的暴力与死亡冲动同样可以是最深邃的生命顿悟。","categories":[{"name":"影评","slug":"影评","permalink":"http://yoursite.com/categories/影评/"}],"tags":[{"name":"北野武","slug":"北野武","permalink":"http://yoursite.com/tags/北野武/"},{"name":"yakuza","slug":"yakuza","permalink":"http://yoursite.com/tags/yakuza/"}]},{"title":"机器学习资料整理","slug":"machine_learning_materials","date":"2018-09-03T10:38:41.948Z","updated":"2018-09-03T11:26:46.850Z","comments":true,"path":"2018/09/03/machine_learning_materials/","link":"","permalink":"http://yoursite.com/2018/09/03/machine_learning_materials/","excerpt":"微积分&emsp;&emsp;Single Variable Calculus - MIT 线性代数&emsp;&emsp;Linear Algebra - MIT","text":"微积分&emsp;&emsp;Single Variable Calculus - MIT 线性代数&emsp;&emsp;Linear Algebra - MIT 概率论与数理统计&emsp;&emsp;(暂无) 凸优化&emsp;&emsp;(暂无) Python&emsp;&emsp;廖雪峰Python教程&emsp;&emsp;Learn python in Y minutes 机器学习&emsp;&emsp;Coursera机器学习 - Andrew Ng&emsp;&emsp;CS229 - Andrew Ng&emsp;&emsp;《统计学习方法》- 李航&emsp;&emsp;《机器学习》 - 周志华&emsp;&emsp;Udacity Machine Learning Engineer Nanodegree 深度学习&emsp;&emsp;Coursera Deep Learning Sepecialization - deeplearning.ai 自然语言系统&emsp;&emsp;(暂无) 推荐系统&emsp;&emsp;推荐系统实践 - 项亮 竞赛&emsp;&emsp;Kaggle","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[{"name":"machinelearning","slug":"machinelearning","permalink":"http://yoursite.com/tags/machinelearning/"},{"name":"deeplearning","slug":"deeplearning","permalink":"http://yoursite.com/tags/deeplearning/"},{"name":"math","slug":"math","permalink":"http://yoursite.com/tags/math/"}]},{"title":"吴恩达机器学习笔记-目录","slug":"machine_learning_note","date":"2018-09-03T09:47:33.890Z","updated":"2018-09-04T14:20:21.857Z","comments":true,"path":"2018/09/03/machine_learning_note/","link":"","permalink":"http://yoursite.com/2018/09/03/machine_learning_note/","excerpt":"","text":"持续更新中…… Coursera机器学习笔记(一) - 监督学习vs无监督学习Coursera机器学习笔记(二) - 单变量线性回归Coursera机器学习笔记(三) - 线代相关知识Coursera机器学习笔记(四) - Octave教程","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[{"name":"machinelearning","slug":"machinelearning","permalink":"http://yoursite.com/tags/machinelearning/"},{"name":"math","slug":"math","permalink":"http://yoursite.com/tags/math/"},{"name":"note","slug":"note","permalink":"http://yoursite.com/tags/note/"}]}]}